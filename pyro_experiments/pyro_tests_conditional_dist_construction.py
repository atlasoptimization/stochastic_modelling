"""
----- GPT4 TRY does not work -----
The goal of this script is to showcase how conditioning can be used to create
conditional distributions and sample from them and how this interacts and 
facilitates inference using pyro-ppl. we illustrate this with code generated by 
gpt4 

For this, do the following:
    1. Imports and definitions
    2. Create stochastic model
    3. Stochastic variational inference
    4. Plots and illustrations
    
Let's assume that we are working with continuous data and a simple linear relationship
for the purposes of this example. Here, we will demonstrate how you can model a joint
 distribution of x and y, and how you can sample from conditional distributions
 p(x|y) and p(y|x) using Pyro.
"""


"""
    1. Imports and definitions
"""
import torch
import pyro
import pyro.distributions as dist
from pyro.infer import SVI, Trace_ELBO
from pyro.optim import Adam


"""
    2. Create stochastic model
"""

# i) Model

def model(x, y=None):
    # Define priors for alpha, beta and sigma
    alpha = pyro.sample('alpha', dist.Normal(0., 10.))
    beta = pyro.sample('beta', dist.Normal(0., 10.))
    sigma = pyro.sample('sigma', dist.Uniform(0., 10.))

    mu = alpha + beta * x
    # Conditional logic for p(y|x)
    return pyro.sample('y', dist.Normal(mu, sigma), obs=y)



# ii) generate data

x = torch.rand(100)
y = 3 * x + 0.5 * torch.randn(100)


"""
    3. Stochastic variational inference
"""

# i) Define variational distribution

def guide(x, y=None):
    # Parameters of the variational distributions for alpha, beta, sigma
    alpha_loc = pyro.param('alpha_loc', torch.tensor(0.))
    alpha_scale = pyro.param('alpha_scale', torch.tensor(1.), constraint=dist.constraints.positive)
    beta_loc = pyro.param('beta_loc', torch.tensor(0.))
    beta_scale = pyro.param('beta_scale', torch.tensor(1.), constraint=dist.constraints.positive)
    sigma_loc = pyro.param('sigma_loc', torch.tensor(1.), constraint=dist.constraints.positive)

    alpha = pyro.sample('alpha', dist.Normal(alpha_loc, alpha_scale))
    beta = pyro.sample('beta', dist.Normal(beta_loc, beta_scale))
    sigma = pyro.sample('sigma', dist.Normal(sigma_loc, 0.1))


# ii) perform SVI

svi = SVI(model, guide, Adam({"lr": 0.005}), loss=Trace_ELBO())
num_steps = 5000
for step in range(num_steps):
    svi.step(x, y)



"""
    4. Plots and illustrations
"""

# Sample from p(y|x)
pyro.sample('y', dist.Normal(pyro.param('alpha_loc').item() + pyro.param('beta_loc').item() * x[0], pyro.param('sigma_loc').item()))

# Sample from p(x|y)
pyro.sample('x', dist.Normal((y[0] - pyro.param('alpha_loc').item()) / pyro.param('beta_loc').item(), pyro.param('sigma_loc').item()))
